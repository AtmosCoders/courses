{
 "metadata": {
  "name": "Iris for beginners"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import iris\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.6.0-dev\n",
        "1.6.1\n",
        "1.2.0rc2\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print iris.__version__\n",
      "print np.__version__\n",
      "import matplotlib\n",
      "print matplotlib.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.6.0-dev\n",
        "1.6.1\n",
        "1.2.0rc2\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Iris and the cube\n",
      "\n",
      "The top level object in Iris is called a cube. A cube contains data and metadata about a single phenomenon and is an implementation of the data model interpreted from the *Climate and Forecast (CF) Metadata Conventions*.\n",
      "\n",
      "Each cube has:\n",
      " * A data array (typically a numpy array).\n",
      " * A \"name\", preferably a CF \"standard name\" to describe the phenomenon that the cube represents.\n",
      " * A collection of coordinates to describe each of the dimensions of the data array. These coordinates are split into two types:\n",
      "    * Dimensioned coordinates are numeric, monotonic and represent a single dimension of the data array. There may be only one dimensioned coordinate per data dimension.\n",
      "    * Auxilliary coordinates can be of any type, including discrete values such as strings, an may represent more than one data dimension.\n",
      "\n",
      "A fuller explanation is available in the [Iris user guide](http://scitools.org.uk/iris/docs/latest/userguide/iris_cubes.html)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets take a simple example to demonstrate the cube concept.\n",
      "\n",
      "Suppose we have a ``(3, 2, 4)`` numpy array:\n",
      "\n",
      "![](files/images/multi_array.png)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Where dimensions 0, 1, and 2 have lengths 3, 2 and 4 respectively.\n",
      "\n",
      "The Iris cube to represent this data would consist of:\n",
      "\n",
      " * a standard name of \"air_temperature\" and a unit of \"kelvin\"\n",
      "\n",
      " * a data array of shape ``(3, 2, 4)``\n",
      "\n",
      " * a coordinate, mapping to dimension 0, consisting of:\n",
      "     * a standard name of \"height\" and unit of \"meters\"\n",
      "     * an array of length 3 representing the 3 height points\n",
      "     \n",
      " * a coordinate, mapping to dimension 1, consisting of:\n",
      "     * a standard name of \"latitude\" and unit of \"degrees\"\n",
      "     * an array of length 2 representing the 2 latitude points\n",
      "     * a coordinate system such that the latitude points could be fully located on the globe\n",
      "     \n",
      " * a coordinate, mapping to dimension 2, consisting of:\n",
      "     * a standard name of \"longitude\" and unit of \"degrees\"\n",
      "     * an array of length 4 representing the 4 longitude points\n",
      "     * a coordinate system such that the longitude points could be fully located on the globe"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pictorially the cube has taken on more information than a simple array:\n",
      "\n",
      "![](files/images/multi_array_to_cube.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Working with a cube"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Whilst it is possible to construct an cube by hand, by far the more common approach to getting hold of a cube is to use the iris load function to access data which already exists in a file.\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = iris.sample_data_path('uk_hires.pp')\n",
      "cubes = iris.load(fname)\n",
      "print cubes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: air_potential_temperature / (K)     (time: 3; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n",
        "1: surface_altitude / (m)              (grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that we've loaded 2 cubes, one representing the \"surface_altitude\" and the other representing \"air_potential_temperature\". We can infer even more detail from this printout, for example, what are the dimensions and shape of the \"air_potential_temperature\" cube?\n",
      "\n",
      "Above we've printed the ``iris.cube.CubeList`` instance representing all of the cubes found in the given filename. However, we can see more detail by printing individual cubes:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "air_pot_temp = cubes[0]\n",
      "print air_pot_temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (time: 3; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n",
        "     Dimension coordinates:\n",
        "          time                           x                      -                 -                    -\n",
        "          model_level_number             -                      x                 -                    -\n",
        "          grid_latitude                  -                      -                 x                    -\n",
        "          grid_longitude                 -                      -                 -                    x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x                      -                 -                    -\n",
        "          level_height                   -                      x                 -                    -\n",
        "          sigma                          -                      x                 -                    -\n",
        "          surface_altitude               -                      -                 x                    x\n",
        "     Derived coordinates:\n",
        "          altitude                       -                      x                 x                    x\n",
        "     Scalar coordinates:\n",
        "          forecast_reference_time: 2009-11-19 04:00:00\n",
        "     Attributes:\n",
        "          STASH: m01s00i004\n",
        "          source: Data from Met Office Unified Model 7.03\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can dig even deeper and print individual coordinates:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print air_pot_temp.coord('model_level_number')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DimCoord(array([ 1,  4,  7, 10, 13, 16, 19], dtype=int32), standard_name='model_level_number', units=Unit('1'), attributes={'positive': 'up'})\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Loading data into Iris"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We've already seen the basic ``load`` function, but we can also control which cubes are actually loaded with *constraints*. The simplest constraint is just a string, which filters cubes based on their name:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = iris.sample_data_path('uk_hires.pp')\n",
      "print iris.load(fname, 'air_potential_temperature')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: air_potential_temperature / (K)     (time: 3; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Note on sample_data_path:\n",
      "\n",
      "Throughout this course we will make use of the sample data that Iris provides. The function ``iris.sample_data_path`` returns the appropriate path to the file in the iris sample data collection. A common mistake for Iris users is to use the ``sample_data_path`` function to access data which is not part of Iris' sample data collection - this is bad practice and is unlikely to work in the future.\n",
      "\n",
      "**Task:**\n",
      "Print the result of ``iris.sample_data_path('uk_hires.pp')`` to verify that it returns a string pointing to a file on your system. Use this string directly in the call to ``iris.load`` and confirm the result is the same as in the previous example e.g.:\n",
      "\n",
      "    print iris.load('/path/to/iris/sampledata/uk_hires.pp', 'air_potential_temperature')\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The three load functions: load, load_cube and load_cubes\n",
      "\n",
      "There are three main load functions in iris: ``load``, ``load_cube`` and ``load_cubes``.\n",
      "\n",
      "1. **load** is a general purpose loading function. Typically this is where all data analysis will start, before more loading is refined with the more controlled loading from the other two functions.\n",
      "2. **load_cube** returns a single cube from the given source(s) and constraint. There will be exactly one cube, or an exception will be raised.\n",
      "3. **load_cubes** returns a list of cubes from the given sources(s) and constraint(s). There will be exactly one cube per constraint, or an exception will be raised.\n",
      "\n",
      "\n",
      "Note: ``load_cube`` is a special case of ``load_cubes`` which can be seen with:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c1, = iris.load(fname, 'surface_altitude')\n",
      "c2 = iris.load_cube(fname, 'surface_altitude')\n",
      "c3, = iris.load_cubes(fname, 'surface_altitude')\n",
      "c1 == c2 == c3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In general, it is a good idea to make use of the ``load_cube``/``load_cubes`` functions rather than the generic ``load`` function in non-exploritary code. Doing so makes your code more resilient to changes in the data source, often results in more readable/maintainable code, and in combination with well defined constraints, will improve load performance."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TASK? What about the different load functions???"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO Wildcard, multiple files..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Constraints\n",
      "\n",
      "Iris' constraints mechanism provides a powerful way to filter a subset of data from a larger collection. We've already seen that constraints can be used at load time to return data of interest from a file, but we can also apply constraints to a single cube, or a list of cubes, using their respective ``extract`` methods:\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cubes = iris.load(fname)\n",
      "print cubes.extract('air_potential_temperature')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: air_potential_temperature / (K)     (time: 3; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The simplest constraint, namely a string which matches a cube's name, is conveniently converted into an actual ``iris.Constraint`` instance wherever needed. However, we could constuct this constraint manually and compare with the previous result:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pot_temperature_constraint = iris.Constraint('air_potential_temperature')\n",
      "print cubes.extract(pot_temperature_constraint)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: air_potential_temperature / (K)     (time: 3; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Constraint constructor also takes arbitrary keywords to constrain coordinate values. For example, to extract model level number 10 from the air potential teperature cube:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pot_temperature_constraint = iris.Constraint('air_potential_temperature', model_level_number=10)\n",
      "print cubes.extract(pot_temperature_constraint)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: air_potential_temperature / (K)     (time: 3; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can pass a list of possible values, and even combine two constraints with ``&``:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cubes.extract('air_potential_temperature' & iris.Constraint(model_level_number=[4, 10]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: air_potential_temperature / (K)     (time: 3; model_level_number: 2; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO: Greater than, less than, cell comparison, floating point..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Saving cubes\n",
      "\n",
      "The ``iris.save`` function provides a convenient interface to save Cube and CubeList instances.\n",
      "\n",
      "To save some cubes to a NetCDF file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris.save(cubes, 'saved_cubes.nc')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ncdump -h saved_cubes.nc | head -n 20\n",
      "!rm saved_cubes.nc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "netcdf saved_cubes {\r\n",
        "dimensions:\r\n",
        "\ttime = UNLIMITED ; // (3 currently)\r\n",
        "\tmodel_level_number = 7 ;\r\n",
        "\tgrid_latitude = 204 ;\r\n",
        "\tgrid_longitude = 187 ;\r\n",
        "\tbnds = 2 ;\r\n",
        "variables:\r\n",
        "\tfloat air_potential_temperature(time, model_level_number, grid_latitude, grid_longitude) ;\r\n",
        "\t\tair_potential_temperature:standard_name = \"air_potential_temperature\" ;\r\n",
        "\t\tair_potential_temperature:units = \"K\" ;\r\n",
        "\t\tair_potential_temperature:ukmo__um_stash_source = \"m01s00i004\" ;\r\n",
        "\t\tair_potential_temperature:grid_mapping = \"rotated_latitude_longitude\" ;\r\n",
        "\t\tair_potential_temperature:coordinates = \"forecast_period forecast_reference_time level_height sigma surface_altitude\" ;\r\n",
        "\tint rotated_latitude_longitude ;\r\n",
        "\t\trotated_latitude_longitude:grid_mapping_name = \"rotated_latitude_longitude\" ;\r\n",
        "\t\trotated_latitude_longitude:longitude_of_prime_meridian = 0. ;\r\n",
        "\t\trotated_latitude_longitude:semi_major_axis = 6371229. ;\r\n",
        "\t\trotated_latitude_longitude:semi_minor_axis = 6371229. ;\r\n",
        "\t\trotated_latitude_longitude:grid_north_pole_latitude = 37.5 ;\r\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Cube attributes\n",
      "\n",
      " * name\n",
      " * standard_name, long_name, var_name\n",
      " \n",
      " * units\n",
      " \n",
      " * data\n",
      " * shape\n",
      " * ndim\n",
      " \n",
      "Question: Why use ``cube.shape`` rather than ``cube.data.shape``?\n",
      "\n",
      " * cell_methods\n",
      " \n",
      "\n",
      "Methods? summary, change_unit... add_???_coord..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Coordinates\n",
      "\n",
      "* coord / coords\n",
      "\n",
      "* name/std_name/long name/var name\n",
      "* coordinate_system\n",
      "* units\n",
      "* shape\n",
      "* points / bounds\n",
      "\n",
      "* guess_bounds"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Exercise:\n",
      "\n",
      "## Part 1\n",
      "\n",
      "Using the file in <> load the data and print the cube list. Store these cubes in a variable called cubes.\n",
      "\n",
      "## Part 2\n",
      "\n",
      "Print a sorted list of unique names for the cubes. (Hint: remember python's ``set`` and ``', '.join(...)`` functionality)\n",
      "\n",
      "## Part 3\n",
      "\n",
      "Extract the \"air pressure at sea level\" cube. Print the minumum, maximum, mean and standard deviation of the cube's data.\n",
      "\n",
      "## Part 4\n",
      "\n",
      "Print the attributes of the cube.\n",
      "\n",
      "## Part 5\n",
      "\n",
      "Print the names of all coordinates on the cube. (Hint: Remember the cube.coords method)\n",
      "\n",
      "## Part 6\n",
      "\n",
      "Get hold of the \"grid_latitude\" coordinate on the cube. Identify whether the cube has bounds. Print the minimum and maximum grid_latitude points in this cube.\n",
      "\n",
      "## Part 7\n",
      "\n",
      "Build constraints for var_name and STASH... WORK ON THIS...\n",
      "\n",
      "## Part 8 (Extension)\n",
      "\n",
      "Use matplotlib's imshow to display the cube's raw data. Don't worry about geolocation (e.g. coastlines), but do add a colorbar."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## More about coordinates on the cube\n",
      "\n",
      "* aux coords\n",
      "* dim coords\n",
      "* aux factories\n",
      "\n",
      "### Creating coordinates and adding them to the cube"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Merging\n",
      "\n",
      "When Iris loads data it tries to reduce the number of cubes returned by collecting together multiple fields with\n",
      "shared metadata into a single multidimensional cube. In Iris, this is known as merging.\n",
      "\n",
      "In order to merge two cubes, they must be identical in everything but a scalar dimension:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = iris.sample_data_path('GloSea4', 'ensemble_00[34].pp')\n",
      "cubes = iris.load_raw(fname, 'surface_temperature')\n",
      "print len(cubes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "incomplete_cubes = cubes.merge(unique=False)\n",
      "print incomplete_cubes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: surface_temperature / (K)           (time: 6; latitude: 145; longitude: 192)\n",
        "1: surface_temperature / (K)           (time: 6; latitude: 145; longitude: 192)\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print incomplete_cubes[0]\n",
      "print '--' * 50\n",
      "print incomplete_cubes[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "surface_temperature / (K)           (time: 6; latitude: 145; longitude: 192)\n",
        "     Dimension coordinates:\n",
        "          time                           x            -               -\n",
        "          latitude                       -            x               -\n",
        "          longitude                      -            -               x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x            -               -\n",
        "     Scalar coordinates:\n",
        "          forecast_reference_time: 2011-07-19 00:00:00\n",
        "     Attributes:\n",
        "          STASH: m01s00i024\n",
        "          source: Data from Met Office Unified Model 7.06\n",
        "     Cell methods:\n",
        "          mean: time (1 hour)\n",
        "----------------------------------------------------------------------------------------------------\n",
        "surface_temperature / (K)           (time: 6; latitude: 145; longitude: 192)\n",
        "     Dimension coordinates:\n",
        "          time                           x            -               -\n",
        "          latitude                       -            x               -\n",
        "          longitude                      -            -               x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x            -               -\n",
        "     Scalar coordinates:\n",
        "          forecast_reference_time: 2011-07-20 00:00:00\n",
        "          realization: 4\n",
        "     Attributes:\n",
        "          STASH: m01s00i024\n",
        "          source: Data from Met Office Unified Model 7.06\n",
        "     Cell methods:\n",
        "          mean: time (1 hour)\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By adding the missing coordinate, we can trigger a merge of the 6 cubes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for cube in cubes:\n",
      "    if not cube.coords('realization'):\n",
      "        cube.add_aux_coord(iris.coords.DimCoord(np.int32(3), 'realization'))\n",
      "\n",
      "merged_cubes = cubes.merge(unique=False)\n",
      "print merged_cubes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: surface_temperature / (K)           (time: 6; forecast_reference_time: 2; latitude: 145; longitude: 192)\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print merged_cubes[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "surface_temperature / (K)           (time: 6; forecast_reference_time: 2; latitude: 145; longitude: 192)\n",
        "     Dimension coordinates:\n",
        "          time                           x                           -            -               -\n",
        "          forecast_reference_time        -                           x            -               -\n",
        "          latitude                       -                           -            x               -\n",
        "          longitude                      -                           -            -               x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x                           x            -               -\n",
        "          realization                    x                           x            -               -\n",
        "     Attributes:\n",
        "          STASH: m01s00i024\n",
        "          source: Data from Met Office Unified Model 7.06\n",
        "     Cell methods:\n",
        "          mean: time (1 hour)\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Load callbacks\n",
      "\n",
      "Sometimes important data exists in a filename rather than in the file itself which needs to be..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = iris.sample_data_path('GloSea4', 'ensemble_00[34].pp')\n",
      "print iris.load(fname, 'surface_temperature')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: surface_temperature / (K)           (time: 6; latitude: 145; longitude: 192)\n",
        "1: surface_temperature / (K)           (time: 6; latitude: 145; longitude: 192)\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "def realization_callback(cube, field, fname):\n",
      "    basename = os.path.basename(fname)\n",
      "    if not cube.coords('realization') and basename.startswith('ensemble_'):\n",
      "        cube.add_aux_coord(iris.coords.DimCoord(np.int32(basename[-6:-3]), 'realization'))\n",
      "\n",
      "print iris.load(fname, callback=realization_callback)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: surface_temperature / (K)           (time: 6; forecast_reference_time: 2; latitude: 145; longitude: 192)\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Exercise\n",
      "\n",
      "Refer back to the file loaded in the previous exercise, this is a genuine file from the Met Office's operational Euro4 model archive (there is a slimmed down version in the repository for those working outside of the Met Office).\n",
      "\n",
      "## Part 1\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Indexing\n",
      "\n",
      "Cubes can be indexed in a familiar manner to that of numpy arrays"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = iris.sample_data_path('uk_hires.pp')\n",
      "cube = iris.load_cube(fname, 'air_potential_temperature')\n",
      "print cube.summary(shorten=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (time: 3; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subcube = cube[..., ::2, 15:35, :10]\n",
      "subcube.summary(shorten=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "'air_potential_temperature / (K)     (time: 3; model_level_number: 4; grid_latitude: 20; grid_longitude: 10)'"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Boolean indexing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subcube = cube[:, cube.coord('model_level_number').points > 10]\n",
      "subcube.summary(shorten=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "'air_potential_temperature / (K)     (time: 3; model_level_number: 3; grid_latitude: 204; grid_longitude: 187)'"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Remember, constraints are better for this task, but sometimes we want to apply boolean indexing on a specific dimension. Here is the equivalent constraint"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subcube_via_constraint = cube.extract(iris.Constraint(model_level_number=lambda c: c > 10))\n",
      "print subcube == subcube_via_constraint"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## UFunc: windows, group by, weights\n",
      "\n",
      "Many standard univariate aggregations exist in Iris, they are written in a way that makes it relatively easy to create our own aggregations:\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = iris.sample_data_path('uk_hires.pp')\n",
      "cube = iris.load_cube(fname, 'air_potential_temperature')\n",
      "print cube.summary(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (time: 3; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cube.collapsed('model_level_number', iris.analysis.MEAN)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (time: 3; grid_latitude: 204; grid_longitude: 187)\n",
        "     Dimension coordinates:\n",
        "          time                           x                 -                    -\n",
        "          grid_latitude                  -                 x                    -\n",
        "          grid_longitude                 -                 -                    x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x                 -                    -\n",
        "          surface_altitude               -                 x                    x\n",
        "     Derived coordinates:\n",
        "          altitude                       -                 x                    x\n",
        "     Scalar coordinates:\n",
        "          forecast_reference_time: 2009-11-19 04:00:00\n",
        "          level_height: 696.667 m, bound=(0.0, 1393.33) m\n",
        "          model_level_number: 10, bound=(1, 19)\n",
        "          sigma: 0.92293, bound=(0.84586, 1.0)\n",
        "     Attributes:\n",
        "          STASH: m01s00i004\n",
        "          history: Mean of air_potential_temperature over model_level_number\n",
        "          source: Data from Met Office Unified Model 7.03\n",
        "     Cell methods:\n",
        "          mean: model_level_number\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Weights must be the same shape as the cube (there is currently no broadcasting being done).\n",
      "There is a function in iris to make this easier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights = np.array([1, 0, 0, 0, 0, 0, 0])\n",
      "weights = iris.util.broadcast_to_shape(weights, cube.shape, (1,))\n",
      "print cube.collapsed('model_level_number', iris.analysis.MEAN, weights=weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (time: 3; grid_latitude: 204; grid_longitude: 187)\n",
        "     Dimension coordinates:\n",
        "          time                           x                 -                    -\n",
        "          grid_latitude                  -                 x                    -\n",
        "          grid_longitude                 -                 -                    x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x                 -                    -\n",
        "          surface_altitude               -                 x                    x\n",
        "     Derived coordinates:\n",
        "          altitude                       -                 x                    x\n",
        "     Scalar coordinates:\n",
        "          forecast_reference_time: 2009-11-19 04:00:00\n",
        "          level_height: 696.667 m, bound=(0.0, 1393.33) m\n",
        "          model_level_number: 10, bound=(1, 19)\n",
        "          sigma: 0.92293, bound=(0.84586, 1.0)\n",
        "     Attributes:\n",
        "          STASH: m01s00i004\n",
        "          history: Mean of air_potential_temperature over model_level_number\n",
        "          source: Data from Met Office Unified Model 7.03\n",
        "     Cell methods:\n",
        "          mean: model_level_number\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Weighted mean"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import iris.analysis.cartography\n",
      "try:\n",
      "    cube.coord('grid_latitude').guess_bounds()\n",
      "    cube.coord('grid_longitude').guess_bounds()\n",
      "except ValueError:\n",
      "    pass\n",
      "grid_areas = iris.analysis.cartography.area_weights(cube)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cube.collapsed(['grid_longitude', 'grid_latitude'], iris.analysis.MEAN, weights=grid_areas)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (time: 3; model_level_number: 7)\n",
        "     Dimension coordinates:\n",
        "          time                           x                      -\n",
        "          model_level_number             -                      x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x                      -\n",
        "          level_height                   -                      x\n",
        "          sigma                          -                      x\n",
        "     Derived coordinates:\n",
        "          altitude                       -                      x\n",
        "     Scalar coordinates:\n",
        "          forecast_reference_time: 2009-11-19 04:00:00\n",
        "          grid_latitude: 1.51455 degrees, bound=(0.13755, 2.89155) degrees\n",
        "          grid_longitude: 358.749 degrees, bound=(357.487, 360.012) degrees\n",
        "          surface_altitude: 399.625 m, bound=(-14.0, 813.25) m\n",
        "     Attributes:\n",
        "          STASH: m01s00i004\n",
        "          history: Mean of air_potential_temperature over grid_longitude, grid_latitude\n",
        "          source: Data from Met Office Unified Model 7.03\n",
        "     Cell methods:\n",
        "          mean: grid_longitude, grid_latitude\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      " * creating a custom ufunc aggregator in Iris?\n",
      "\n",
      "mean."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Iteration (and izip)\n",
      "\n",
      "We can loop through all desired subcubes in a larger cube using the ``slices`` method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = iris.sample_data_path('uk_hires.pp')\n",
      "cube = iris.load_cube(fname, 'air_potential_temperature' & iris.Constraint(model_level_number=1))\n",
      "print cube.summary(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (time: 3; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 168
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for subcube in cube.slices(['grid_latitude', 'grid_longitude']):\n",
      "    print subcube.summary(shorten=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (grid_latitude: 204; grid_longitude: 187)\n",
        "air_potential_temperature / (K)     (grid_latitude: 204; grid_longitude: 187)\n",
        "air_potential_temperature / (K)     (grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 169
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "izip - why?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from iris.iterate import izip\n",
      "\n",
      "# WHY WOULD YOU DO THIS AND NOT JUST HAVE \"MEAN\" A VARIABLE?...\n",
      "for mean, timestep in izip(cube.collapsed('time', iris.analysis.MEAN), cube, coords=['grid_latitude', 'grid_longitude']):\n",
      "    print mean.summary(True)\n",
      "    print timestep.summary(True)\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (grid_latitude: 204; grid_longitude: 187)\n",
        "air_potential_temperature / (K)     (grid_latitude: 204; grid_longitude: 187)\n",
        "\n",
        "air_potential_temperature / (K)     (grid_latitude: 204; grid_longitude: 187)\n",
        "air_potential_temperature / (K)     (grid_latitude: 204; grid_longitude: 187)\n",
        "\n",
        "air_potential_temperature / (K)     (grid_latitude: 204; grid_longitude: 187)\n",
        "air_potential_temperature / (K)     (grid_latitude: 204; grid_longitude: 187)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 173
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Plotting\n",
      "\n",
      "## maths\n",
      "\n",
      "## stats\n",
      "\n",
      "## Masked data\n",
      "\n",
      "## Performance tricks\n",
      "\n",
      " * data loading\n",
      " \n",
      "\n",
      "\n",
      "## Future\n",
      "\n",
      " * IPython notebook (wakari, nbviewer)\n",
      " * OpeNDaP (sort out capitalisation)\n",
      " * biggus\n",
      " * cartopy\n",
      " \n",
      " \n",
      "## Thea\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}