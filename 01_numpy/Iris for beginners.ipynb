{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import iris"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Iris and the cube\n",
      "\n",
      "The top level object in Iris is called a cube. A cube contains data and metadata about a single phenomenon and is an implementation of the data model interpreted from the *Climate and Forecast (CF) Metadata Conventions*.\n",
      "\n",
      "Each cube has:\n",
      " * A data array (typically a numpy array).\n",
      " * A \"name\", preferably a CF \"standard name\" to describe the phenomenon that the cube represents.\n",
      " * A collection of coordinates to describe each of the dimensions of the data array. These coordinates are split into two types:\n",
      "    * Dimensioned coordinates are numeric, monotonic and represent a single dimension of the data array. There may be only one dimensioned coordinate per data dimension.\n",
      "    * Auxilliary coordinates can be of any type, including discrete values such as strings, an may represent more than one data dimension.\n",
      "\n",
      "A fuller explanation is available in the [Iris user guide](http://scitools.org.uk/iris/docs/latest/userguide/iris_cubes.html)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets take a simple example to demonstrate the cube concept.\n",
      "\n",
      "Suppose we have a ``(3, 2, 4)`` numpy array:\n",
      "\n",
      "![](files/images/multi_array.png)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Where dimensions 0, 1, and 2 have lengths 3, 2 and 4 respectively.\n",
      "\n",
      "The Iris cube to represent this data would consist of:\n",
      "\n",
      " * a standard name of \"air_temperature\" and a unit of \"kelvin\"\n",
      "\n",
      " * a data array of shape ``(3, 2, 4)``\n",
      "\n",
      " * a coordinate, mapping to dimension 0, consisting of:\n",
      "     * a standard name of \"height\" and unit of \"meters\"\n",
      "     * an array of length 3 representing the 3 height points\n",
      "     \n",
      " * a coordinate, mapping to dimension 1, consisting of:\n",
      "     * a standard name of \"latitude\" and unit of \"degrees\"\n",
      "     * an array of length 2 representing the 2 latitude points\n",
      "     * a coordinate system such that the latitude points could be fully located on the globe\n",
      "     \n",
      " * a coordinate, mapping to dimension 2, consisting of:\n",
      "     * a standard name of \"longitude\" and unit of \"degrees\"\n",
      "     * an array of length 4 representing the 4 longitude points\n",
      "     * a coordinate system such that the longitude points could be fully located on the globe"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pictorially the cube has taken on more information than a simple array:\n",
      "\n",
      "![](files/images/multi_array_to_cube.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Working with a cube"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Whilst it is possible to construct an cube by hand, by far the more common approach to getting hold of a cube is to use the iris load function to access data which already exists in a file.\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = iris.sample_data_path('uk_hires.pp')\n",
      "cubes = iris.load(fname)\n",
      "print cubes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: air_potential_temperature / (K)     (time: 3; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n",
        "1: surface_altitude / (m)              (grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that we've loaded 2 cubes, one representing the \"surface_altitude\" and the other representing \"air_potential_temperature\". We can infer even more detail from this printout, for example, what are the dimensions and shape of the \"air_potential_temperature\" cube?\n",
      "\n",
      "Above we've printed the ``iris.cube.CubeList`` instance representing all of the cubes found in the given filename. However, we can see more detail by printing individual cubes:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "air_pot_temp = cubes[0]\n",
      "print air_pot_temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (time: 3; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n",
        "     Dimension coordinates:\n",
        "          time                           x                      -                 -                    -\n",
        "          model_level_number             -                      x                 -                    -\n",
        "          grid_latitude                  -                      -                 x                    -\n",
        "          grid_longitude                 -                      -                 -                    x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x                      -                 -                    -\n",
        "          level_height                   -                      x                 -                    -\n",
        "          sigma                          -                      x                 -                    -\n",
        "          surface_altitude               -                      -                 x                    x\n",
        "     Derived coordinates:\n",
        "          altitude                       -                      x                 x                    x\n",
        "     Scalar coordinates:\n",
        "          forecast_reference_time: 2009-11-19 04:00:00\n",
        "     Attributes:\n",
        "          STASH: m01s00i004\n",
        "          source: Data from Met Office Unified Model 7.03\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can dig even deeper and print individual coordinates:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print air_pot_temp.coord('model_level_number')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DimCoord(array([ 1,  4,  7, 10, 13, 16, 19], dtype=int32), standard_name='model_level_number', units=Unit('1'), attributes={'positive': 'up'})\n"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Loading data into Iris"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We've already seen the basic ``load`` function, but we can also control which cubes are actually loaded with *constraints*. The simplest constraint is just a string, which filters cubes based on their name:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = iris.sample_data_path('uk_hires.pp')\n",
      "print iris.load(fname, 'air_potential_temperature')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: air_potential_temperature / (K)     (time: 3; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Note on sample_data_path:\n",
      "\n",
      "Throughout this course we will make use of the sample data that Iris provides. The function ``iris.sample_data_path`` returns the appropriate path to the file in the iris sample data collection. A common mistake for Iris users is to use the ``sample_data_path`` function to access data which is not part of Iris' sample data collection - this is bad practice and is unlikely to work in the future.\n",
      "\n",
      "**Task:**\n",
      "Print the result of ``iris.sample_data_path('uk_hires.pp')`` to verify that it returns a string pointing to a file on your system. Use this string directly in the call to ``iris.load`` and confirm the result is the same as in the previous example e.g.:\n",
      "\n",
      "    print iris.load('/path/to/iris/sample/data/uk_hires.pp', 'air_potential_temperature')\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The three load functions: load, load_cube and load_cubes\n",
      "\n",
      "There are three main load functions in iris: ``load``, ``load_cube`` and ``load_cubes``.\n",
      "\n",
      "1. **load** is a general purpose loading function. Typically this is where all data analysis will start, before more loading is refined with the more controlled loading from the other two functions.\n",
      "2. **load_cube** returns a single cube from the given source(s) and constraint. There will be exactly one cube, or an exception will be raised.\n",
      "3. **load_cubes** returns a list of cubes from the given sources(s) and constraint(s). There will be exactly one cube per constraint, or an exception will be raised.\n",
      "\n",
      "\n",
      "Note: ``load_cube`` is a special case of ``load_cubes`` which can be seen with:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c1, = iris.load(fname, 'surface_altitude')\n",
      "c2 = iris.load_cube(fname, 'surface_altitude')\n",
      "c3, = iris.load_cubes(fname, 'surface_altitude')\n",
      "c1 == c2 == c3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 81,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 81
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In general, it is a good idea to make use of the ``load_cube``/``load_cubes`` functions rather than the generic ``load`` function in non-exploritary code. Doing so makes your code more resilient to changes in the data source, often results in more readable/maintainable code, and in combination with well defined constraints, will improve load performance."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TASK? What about the different load functions???"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO Wildcard, multiple files..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Constraints\n",
      "\n",
      "Iris' constraints mechanism provides a powerful way to filter a subset of data from a larger collection. We've already seen that constraints can be used at load time to return data of interest from a file, but we can also apply constraints to a single cube, or a list of cubes, using their respective ``extract`` methods:\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cubes = iris.load(fname)\n",
      "print cubes.extract('air_potential_temperature')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: air_potential_temperature / (K)     (time: 3; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The simplest constraint, namely a string which matches a cube's name, is conveniently converted into an actual ``iris.Constraint`` instance wherever needed. However, we could constuct this constraint manually and compare with the previous result:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pot_temperature_constraint = iris.Constraint('air_potential_temperature')\n",
      "print cubes.extract(pot_temperature_constraint)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: air_potential_temperature / (K)     (time: 3; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Constraint constructor also takes arbitrary keywords to constrain coordinate values. For example, to extract model level number 10 from the air potential teperature cube:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pot_temperature_constraint = iris.Constraint('air_potential_temperature', model_level_number=10)\n",
      "print cubes.extract(pot_temperature_constraint)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: air_potential_temperature / (K)     (time: 3; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can pass a list of possible values, and even combine two constraints with ``&``:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cubes.extract('air_potential_temperature' & iris.Constraint(model_level_number=[4, 10]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: air_potential_temperature / (K)     (time: 3; model_level_number: 2; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO: Greater than, less than, cell comparison, floating point..."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Saving cubes\n",
      "\n",
      "Iris .save"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Cube attributes\n",
      "\n",
      "## Coordinates\n",
      "\n",
      "## Coordinate attributes\n",
      "\n",
      "## Load callbacks\n",
      "\n",
      "## Indexing\n",
      "\n",
      "## Iteration (and izip)\n",
      "\n",
      "## Plotting\n",
      "\n",
      "## Ufunc, windows, group by\n",
      "\n",
      " * creating a custom ufunc aggregator in Iris?\n",
      "\n",
      "## maths\n",
      "\n",
      "## stats\n",
      "\n",
      "## Masked data\n",
      "\n",
      "## Merging\n",
      "\n",
      "## Performance tricks\n",
      "\n",
      " * data loading\n",
      " \n",
      "\n",
      "\n",
      "## Future\n",
      "\n",
      " * IPython notebook (wakari, nbviewer)\n",
      " * OpeNDaP (sort out capitalisation)\n",
      " * biggus\n",
      " * cartopy\n",
      " \n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}