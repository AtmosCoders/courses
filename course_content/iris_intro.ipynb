{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## An introduction to Iris"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import iris\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print iris.__version__\n",
      "print np.__version__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.6.0\n",
        "1.6.2\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Iris and the cube\n",
      "\n",
      "The top level object in Iris is called a cube. A cube contains data and metadata about a single phenomenon and is an implementation of the data model interpreted from the *Climate and Forecast (CF) Metadata Conventions*.\n",
      "\n",
      "Each cube has:\n",
      "\n",
      " * A data array (typically a numpy array).\n",
      " * A \"name\", preferably a CF \"standard name\" to describe the phenomenon that the cube represents.\n",
      " * A collection of coordinates to describe each of the dimensions of the data array. These coordinates are split into two types:\n",
      "    * Dimensioned coordinates are numeric, monotonic and represent a single dimension of the data array. There may be only one dimensioned coordinate per data dimension.\n",
      "    * Auxilliary coordinates can be of any type, including discrete values such as strings, an may represent more than one data dimension.\n",
      "\n",
      "A fuller explanation is available in the [Iris user guide](http://scitools.org.uk/iris/docs/latest/userguide/iris_cubes.html)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's take a simple example to demonstrate the cube concept.\n",
      "\n",
      "Suppose we have a ``(3, 2, 4)`` numpy array:\n",
      "\n",
      "![](files/images/multi_array.png)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Where dimensions 0, 1, and 2 have lengths 3, 2 and 4 respectively.\n",
      "\n",
      "The Iris cube to represent this data may consist of:\n",
      "\n",
      " * a standard name of \"air_temperature\" and units of \"kelvin\"\n",
      "\n",
      " * a data array of shape ``(3, 2, 4)``\n",
      "\n",
      " * a coordinate, mapping to dimension 0, consisting of:\n",
      "     * a standard name of \"height\" and units of \"meters\"\n",
      "     * an array of length 3 representing the 3 height points\n",
      "     \n",
      " * a coordinate, mapping to dimension 1, consisting of:\n",
      "     * a standard name of \"latitude\" and units of \"degrees\"\n",
      "     * an array of length 2 representing the 2 latitude points\n",
      "     * a coordinate system such that the latitude points could be fully located on the globe\n",
      "     \n",
      " * a coordinate, mapping to dimension 2, consisting of:\n",
      "     * a standard name of \"longitude\" and units of \"degrees\"\n",
      "     * an array of length 4 representing the 4 longitude points\n",
      "     * a coordinate system such that the longitude points could be fully located on the globe"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pictorially the cube has taken on more information than a simple array:\n",
      "\n",
      "![](files/images/multi_array_to_cube.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Working with a cube"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Whilst it is possible to construct an cube by hand, by far the more common approach to getting hold of a cube is to use the iris load function to access data which already exists in a file.\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = iris.sample_data_path('uk_hires.pp')\n",
      "cubes = iris.load(fname)\n",
      "print cubes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: air_potential_temperature / (K)     (time: 3; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n",
        "1: surface_altitude / (m)              (grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that we've loaded 2 cubes, one representing the \"surface_altitude\" and the other representing \"air_potential_temperature\". We can infer even more detail from this printout, for example, what are the dimensions and shape of the \"air_potential_temperature\" cube?\n",
      "\n",
      "Above we've printed the ``iris.cube.CubeList`` instance representing all of the cubes found in the given filename. However, we can see more detail by printing individual cubes:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "air_pot_temp = cubes[0]\n",
      "print air_pot_temp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (time: 3; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n",
        "     Dimension coordinates:\n",
        "          time                           x                      -                 -                    -\n",
        "          model_level_number             -                      x                 -                    -\n",
        "          grid_latitude                  -                      -                 x                    -\n",
        "          grid_longitude                 -                      -                 -                    x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x                      -                 -                    -\n",
        "          level_height                   -                      x                 -                    -\n",
        "          sigma                          -                      x                 -                    -\n",
        "          surface_altitude               -                      -                 x                    x\n",
        "     Derived coordinates:\n",
        "          altitude                       -                      x                 x                    x\n",
        "     Scalar coordinates:\n",
        "          forecast_reference_time: 2009-11-19 04:00:00\n",
        "     Attributes:\n",
        "          STASH: m01s00i004\n",
        "          source: Data from Met Office Unified Model 7.03\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can dig even deeper and print individual coordinates:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print air_pot_temp.coord('model_level_number')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DimCoord(array([ 1,  4,  7, 10, 13, 16, 19], dtype=int32), standard_name='model_level_number', units=Unit('1'), attributes={'positive': 'up'})\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Cube attributes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cube = iris.load_cube(iris.sample_data_path('A1B_north_america.nc'))\n",
      "print cube"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_temperature / (K)               (time: 240; latitude: 37; longitude: 49)\n",
        "     Dimension coordinates:\n",
        "          time                           x              -              -\n",
        "          latitude                       -              x              -\n",
        "          longitude                      -              -              x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x              -              -\n",
        "     Scalar coordinates:\n",
        "          forecast_reference_time: 1859-09-01 06:00:00\n",
        "          height: 1.5 m\n",
        "     Attributes:\n",
        "          Conventions: CF-1.5\n",
        "          Model scenario: A1B\n",
        "          STASH: m01s03i236\n",
        "          source: Data from Met Office Unified Model 6.05\n",
        "     Cell methods:\n",
        "          mean: time (6 hour)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To access a cube's data array the **``data``** property exists, this is either a numpy array or in some cases a numpy masked array. It is very important to note that for most of the supported filetypes in Iris, the data isn't actually loaded for a cube until you request the cube's data via this property (either directly or indirectly). After you've accessed the data once, it is stored on the cube and thus wont be loaded again.\n",
      "\n",
      "To find the shape of a cube's data it is possible to do ``cube.data.shape`` or ``cube.data.ndim``, but this will trigger any unloaded data to be loaded, therefore ``shape`` and ``ndim`` are properties available directly on the cube which do not unnecessarily load data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cube.shape\n",
      "print cube.ndim\n",
      "print type(cube.data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(240, 37, 49)\n",
        "3\n",
        "<type 'numpy.ndarray'>\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The ``standard_name``, ``long_name`` and to an extent ``var_name`` are all attributes to describe the phenomenon that the cube represent. The **``name()``** method is a convenience which looks at the attributes in that order, returning the first non-empty string. To rename a cube, it is possible to set the attributes manually, but it is generally easier to use the **``rename()``** method.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cube.standard_name\n",
      "print cube.long_name\n",
      "print cube.var_name\n",
      "print cube.name()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_temperature\n",
        "None\n",
        "air_temperature\n",
        "air_temperature\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cube.rename(\"A name that isn't a valid CF standard name\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cube.standard_name\n",
      "print cube.long_name\n",
      "print cube.var_name\n",
      "print cube.name()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "None\n",
        "A name that isn't a valid CF standard name\n",
        "None\n",
        "A name that isn't a valid CF standard name\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The **``units``** attribute on a cube tells us the units of the numbers held in the data array. We can manually change the units, or better, we can convert the cube to another unit using the **``convert_units``** method, which will automatically update the data array."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cube.units\n",
      "print cube.data.max()\n",
      "cube.convert_units('Celsius')\n",
      "print cube.units\n",
      "print cube.data.max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "K\n",
        "306.073\n",
        "Celsius\n",
        "32.9233\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A cube has a dictionary for extra general purpose attributes, which can be accessed with the ``cube.attributes`` attribute:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cube.attributes\n",
      "print cube.attributes['STASH']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'Model scenario': 'A1B', 'Conventions': 'CF-1.5', 'STASH': STASH(model=1, section=3, item=236), 'source': 'Data from Met Office Unified Model 6.05'}\n",
        "m01s03i236\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A less frequently used attribute on a cube is its ``cell_methods``. The cell methods are a way to store information about the processing that has taken place on the cube."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for cell_method in cube.cell_methods:\n",
      "    print cell_method"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "mean: time (6 hour)\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case we can see that the cube is has been produced by taking a mean of forecasts sampled at 6 hourly intervals (we need to look at the time coordinate to identify any more information)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Coordinates\n",
      "\n",
      "As we've seen, cubes need coordinate information to help us describe the underlying phenomenon. Typically a cube's coordinates are accessed with the **``coords``** or **``coord``** methods. The latter *must* return exactly one coordinate for the given parameter filters, where the former returns a list of matching coordinates, possibly of length 0.\n",
      "\n",
      "For example, to access the time coordinate, and print the first 4 times:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time = cube.coord('time')\n",
      "print time[:4]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DimCoord([1860-06-01 00:00:00, 1861-06-01 00:00:00, 1862-06-01 00:00:00,\n",
        "       1863-06-01 00:00:00], bounds=[[1859-12-01 00:00:00, 1860-12-01 00:00:00],\n",
        "       [1860-12-01 00:00:00, 1861-12-01 00:00:00],\n",
        "       [1861-12-01 00:00:00, 1862-12-01 00:00:00],\n",
        "       [1862-12-01 00:00:00, 1863-12-01 00:00:00]], standard_name=u'time', calendar=u'360_day', var_name='time')\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Along with the cell method from the previous section, we can now see that this cube represents the mean annual air temperature, sampled every 6 hours, starting in 1860."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The coordinate interface is very similar to that of a cube. The attributes which exist on both cubes and coordinates are: ``standard_name``, ``long_name``, ``var_name``, ``units``, ``attributes`` and ``shape``. Similarly, the **``name()``**, **``rename()``** and **``convert_units()``** methods also exist on a coordinate."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A coordinate does not have ``data``, instead it has ``points`` and ``bounds`` (``bounds`` may be ``None``). In Iris, time coordinates are currently represented as \"a number since an epoch\":"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print repr(time.units)\n",
      "print time.points[:4]\n",
      "print time.bounds[:4]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Unit('hours since 1970-01-01 00:00:00', calendar='360_day')\n",
        "[-946800. -938160. -929520. -920880.]\n",
        "[[-951120. -942480.]\n",
        " [-942480. -933840.]\n",
        " [-933840. -925200.]\n",
        " [-925200. -916560.]]\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These numbers can be converted to datetime objects with the unit's ``num2date`` method. Dates can be converted back again with the ``date2num`` method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print time.units.num2date(time.points[:4])\n",
      "print time.units.date2num(datetime.datetime(1970, 2, 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'datetime' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-16-d36ecc973027>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum2date\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate2num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1970\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'datetime' is not defined"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1860-06-01 00:00:00 1861-06-01 00:00:00 1862-06-01 00:00:00\n",
        " 1863-06-01 00:00:00]\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another important attribute on a coordinate is its coordinate system. Coordinate systems may be ``None`` for trivial coordinates, but particularly for spatial coordinates, they may be complex definitions of things such as the projection, ellipse and/or datum."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lat = cube.coord('latitude')\n",
      "print lat.coord_system"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "GeogCS(6371229.0)\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case, the latitude's coordinate system is a simple geographic latitude on a spherical globe of radius 6371229 (meters)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sometimes it is desirable to add bounds to a coordinate which doesn't have any. This is often the case for creating \"block\" type plots where a coordinate should be able to represent an interval of values, rather than a single point. The **``guess_bounds``** method on a coordinate is useful in this regard. For example, the latitude coordinate previously obtained does not have bounds, but we can either set some manually, or use the ``guess_bounds`` method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print lat.points[:4]\n",
      "print lat.bounds\n",
      "if lat.bounds is None:\n",
      "    lat.guess_bounds()\n",
      "print lat.bounds[:4]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 15.    16.25  17.5   18.75]\n",
        "None\n",
        "[[ 14.375  15.625]\n",
        " [ 15.625  16.875]\n",
        " [ 16.875  18.125]\n",
        " [ 18.125  19.375]]\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 1:\n",
      "\n",
      "1\\. Using the file in ``iris.sample_data_path('atlantic_profiles.nc')`` load the data and print the cube list. Store these cubes in a variable called cubes.\n",
      "\n",
      "2\\. Print a sorted list of unique names for the cubes.\n",
      "\n",
      "3\\. Extract the \"sea_water_potential_temperature\" cube. Print the minimum, maximum, mean and standard deviation of the cube's data.\n",
      "\n",
      "4\\. Print the attributes of the cube.\n",
      "\n",
      "5\\. Print the names of all coordinates on the cube. (Hint: Remember the cube.coords method)\n",
      "\n",
      "6\\. Get hold of the \"latitude\" coordinate on the cube. Identify whether the cube has bounds. Print the minimum and maximum latitude points in this cube."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Loading data into Iris"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We've already seen the basic ``load`` function, but we can also control which cubes are actually loaded with *constraints*. The simplest constraint is just a string, which filters cubes based on their name:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = iris.sample_data_path('uk_hires.pp')\n",
      "print iris.load(fname, 'air_potential_temperature')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: air_potential_temperature / (K)     (time: 3; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Note on sample_data_path:\n",
      "\n",
      "Throughout this course we will make use of the sample data that Iris provides. The function ``iris.sample_data_path`` returns the appropriate path to the file in the iris sample data collection. A common mistake for Iris users is to use the ``sample_data_path`` function to access data which is not part of Iris's sample data collection - this is bad practice and is unlikely to work in the future.\n",
      "\n",
      "**Exercise 2:**\n",
      "Print the result of ``iris.sample_data_path('uk_hires.pp')`` to verify that it returns a string pointing to a file on your system. Use this string directly in the call to ``iris.load`` and confirm the result is the same as in the previous example e.g.:\n",
      "\n",
      "    print iris.load('/path/to/iris/sampledata/uk_hires.pp', 'air_potential_temperature')\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The three load functions: load, load_cube and load_cubes\n",
      "\n",
      "There are three main load functions in iris: ``load``, ``load_cube`` and ``load_cubes``.\n",
      "\n",
      "1. **load** is a general purpose loading function. Typically this is where all data analysis will start, before more loading is refined with the more controlled loading from the other two functions.\n",
      "2. **load_cube** returns a single cube from the given source(s) and constraint. There will be exactly one cube, or an exception will be raised.\n",
      "3. **load_cubes** returns a list of cubes from the given sources(s) and constraint(s). There will be exactly one cube per constraint, or an exception will be raised.\n",
      "\n",
      "\n",
      "Note: ``load_cube`` is a special case of ``load_cubes`` which can be seen with:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c1, = iris.load(fname, 'surface_altitude')\n",
      "c2 = iris.load_cube(fname, 'surface_altitude')\n",
      "c3, = iris.load_cubes(fname, 'surface_altitude')\n",
      "c1 == c2 == c3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In general, it is a good idea to make use of the ``load_cube``/``load_cubes`` functions rather than the generic ``load`` function in non-exploratory code. Doing so makes your code more resilient to changes in the data source, often results in more readable/maintainable code, and in combination with well defined constraints, will improve load performance."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The load functions all accept a list of filenames to load, and any of the filenames can be \"glob\" patterns (http://docs.python.org/2/library/glob.html).\n",
      "\n",
      "**Exercise 2 continued:** Read in the files found at ``iris.sample_data_path('GloSea4', 'ensemble_010.pp')`` and ``iris.sample_data_path('GloSea4', 'ensemble_011.pp')`` using a single load call. Do this by:\n",
      "\n",
      "1. providing a list of the two filenames.\n",
      "2. providing a suitable glob pattern."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Constraints\n",
      "\n",
      "Iris's constraints mechanism provides a powerful way to filter a subset of data from a larger collection. We've already seen that constraints can be used at load time to return data of interest from a file, but we can also apply constraints to a single cube, or a list of cubes, using their respective ``extract`` methods:\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = iris.sample_data_path('uk_hires.pp')\n",
      "cubes = iris.load(fname)\n",
      "print cubes.extract('air_potential_temperature')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: air_potential_temperature / (K)     (time: 3; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The simplest constraint, namely a string which matches a cube's name, is conveniently converted into an actual ``iris.Constraint`` instance wherever needed. However, we could construct this constraint manually and compare with the previous result:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pot_temperature_constraint = iris.Constraint('air_potential_temperature')\n",
      "print cubes.extract(pot_temperature_constraint)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: air_potential_temperature / (K)     (time: 3; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Constraint constructor also takes arbitrary keywords to constrain coordinate values. For example, to extract model level number 10 from the air potential teperature cube:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pot_temperature_constraint = iris.Constraint('air_potential_temperature', model_level_number=10)\n",
      "print cubes.extract(pot_temperature_constraint)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: air_potential_temperature / (K)     (time: 3; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can pass a list of possible values, and even combine two constraints with ``&``:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cubes.extract('air_potential_temperature' & iris.Constraint(model_level_number=[4, 10]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: air_potential_temperature / (K)     (time: 3; model_level_number: 2; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can define arbitrary functions which operate on each cell of a coordinate. This is a common thing to do for floating point coordinates, where exact equality is non-trivial."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def less_than_10(cell):\n",
      "    \"\"\"Return True for values which are less than 10.\"\"\"\n",
      "    return cell < 10\n",
      "\n",
      "print cubes.extract(iris.Constraint('air_potential_temperature', model_level_number=less_than_10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: air_potential_temperature / (K)     (time: 3; model_level_number: 3; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Because Iris cells represent both point and bound, cell comparison can sometimes be counter-intuitive:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cell_comparison(cell, value):\n",
      "    print 'cell > {0!r} is {1}'.format(value, cell > value)\n",
      "    print 'cell >= {0!r} is {1}'.format(value, cell >= value)\n",
      "    print 'cell == {0!r} is {1}'.format(value, cell == value)\n",
      "    print 'cell <= {0!r} is {1}'.format(value, cell <= value)\n",
      "    print 'cell < {0!r} is {1}'.format(value, cell < value)\n",
      "\n",
      "cell = iris.coords.Cell(point=10, bound=[8, 12])\n",
      "cell_comparison(cell, 12)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cell > 12 is False\n",
        "cell >= 12 is True\n",
        "cell == 12 is True\n",
        "cell <= 12 is True\n",
        "cell < 12 is False\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you want full control of how cell comparison is taking place, you can always compare with another cell:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cell_1 = iris.coords.Cell(point=10, bound=[8, 12])\n",
      "cell_2 = iris.coords.Cell(point=11, bound=None)\n",
      "\n",
      "cell_comparison(cell_1, 11)\n",
      "print\n",
      "cell_comparison(cell_1, cell_2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cell > 11 is False\n",
        "cell >= 11 is True\n",
        "cell == 11 is True\n",
        "cell <= 11 is True\n",
        "cell < 11 is False\n",
        "\n",
        "cell > Cell(point=11, bound=None) is False\n",
        "cell >= Cell(point=11, bound=None) is False\n",
        "cell == Cell(point=11, bound=None) is False\n",
        "cell <= Cell(point=11, bound=None) is True\n",
        "cell < Cell(point=11, bound=None) is True\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is common to want to build a constraint for time. With Iris < v1.6, because of the way that time coordinate have been implemented, it was harder to build time constraints than we would like (as you need to know the units that your time coordinate is in. For example, it could be \"hours since 2000-01-01\", \"days since 1970-01-01\" or any other number of reference epoch's and units).\n",
      "\n",
      "In practice this meant we needed to get hold of the \"time\" coordinate *before* we could build the constraint."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import datetime\n",
      "\n",
      "air_pot_temp = cubes.extract('air_potential_temperature', strict=True)\n",
      "\n",
      "time_coord = air_pot_temp.coord('time')\n",
      "date = datetime.datetime(2009, 11, 19, 11, 0)\n",
      "date_in_time_units = time_coord.units.date2num(date)\n",
      "print '{} == {} {}'.format(date, date_in_time_units, time_coord.units)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2009-11-19 11:00:00 == 349619.0 hours since 1970-01-01 00:00:00\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time_constraint = iris.Constraint(time=lambda c: c >= date_in_time_units)\n",
      "print air_pot_temp.extract(time_constraint).summary(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (time: 2; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, since v1.6 this hase been made simpler by the ability to compare against cells containing datetimes. The functionality can be enabled **globally within the session** (and will be enabled by default in future release of iris) with:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris.FUTURE.cell_datetime_objects = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With this set, it is now possible to do the same constraint by simply:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time_constraint = iris.Constraint(time=lambda c: c >= datetime.datetime(2009, 11, 19, 11, 0))\n",
      "print air_pot_temp.extract(time_constraint).summary(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (time: 2; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Further functionality has been added to isolate individual components of a datetime via the [PartialDateTime](http://scitools.org.uk/iris/docs/latest/iris/iris/time.html?highlight=partial#iris.time.PartialDateTime) class. In this case we can extract the timestep at the 11th hour with:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from iris.time import PartialDateTime\n",
      "eleventh_hour = iris.Constraint(time=PartialDateTime(hour=11))\n",
      "print air_pot_temp.extract(eleventh_hour).summary(True)\n",
      "print air_pot_temp.extract(eleventh_hour).coord('time')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n",
        "DimCoord([2009-11-19 11:00:00], standard_name='time', calendar='gregorian')\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 3:**\n",
      "\n",
      "1. Write a function, which when given a cube, returns True or False depending on whether a cell method exists.\n",
      "2. Use this function as a value for the ``iris.Constraint`` **cube_func** keyword, and load the file in ``iris.sample_data_path('A1B_north_america.nc')`` such that only cubes with cell methods are loaded (note: in this case, that is all that exists in the file)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Saving cubes\n",
      "\n",
      "The ``iris.save`` function provides a convenient interface to save Cube and CubeList instances.\n",
      "\n",
      "To save some cubes to a NetCDF file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iris.save(cubes, 'saved_cubes.nc')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ncdump -h saved_cubes.nc | head -n 20\n",
      "!rm saved_cubes.nc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "netcdf saved_cubes {\r\n",
        "dimensions:\r\n",
        "\ttime = UNLIMITED ; // (3 currently)\r\n",
        "\tmodel_level_number = 7 ;\r\n",
        "\tgrid_latitude = 204 ;\r\n",
        "\tgrid_longitude = 187 ;\r\n",
        "\tbnds = 2 ;\r\n",
        "variables:\r\n",
        "\tfloat air_potential_temperature(time, model_level_number, grid_latitude, grid_longitude) ;\r\n",
        "\t\tair_potential_temperature:standard_name = \"air_potential_temperature\" ;\r\n",
        "\t\tair_potential_temperature:units = \"K\" ;\r\n",
        "\t\tair_potential_temperature:ukmo__um_stash_source = \"m01s00i004\" ;\r\n",
        "\t\tair_potential_temperature:grid_mapping = \"rotated_latitude_longitude\" ;\r\n",
        "\t\tair_potential_temperature:coordinates = \"forecast_period forecast_reference_time level_height sigma surface_altitude\" ;\r\n",
        "\tint rotated_latitude_longitude ;\r\n",
        "\t\trotated_latitude_longitude:grid_mapping_name = \"rotated_latitude_longitude\" ;\r\n",
        "\t\trotated_latitude_longitude:longitude_of_prime_meridian = 0. ;\r\n",
        "\t\trotated_latitude_longitude:semi_major_axis = 6371229. ;\r\n",
        "\t\trotated_latitude_longitude:semi_minor_axis = 6371229. ;\r\n",
        "\t\trotated_latitude_longitude:grid_north_pole_latitude = 37.5 ;\r\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Extra keywords can be passed to specific fileformat savers.\n",
      "\n",
      "**Task:** Go to the iris reference documentation for ``iris.save``. Which fileformats can currently be saved to? Which keywords are accepted to ``iris.save`` when saving a PP file?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Merging\n",
      "\n",
      "When Iris loads data it tries to reduce the number of cubes returned by collecting together multiple fields with\n",
      "shared metadata into a single multidimensional cube. In Iris, this is known as merging.\n",
      "\n",
      "In order to merge two cubes, they must be identical in everything but a scalar dimension.\n",
      "\n",
      "If we load the fields from two ensemble members from the GloSea4 model sample data we see we have 12 fields before any merge takes place:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = iris.sample_data_path('GloSea4', 'ensemble_00[34].pp')\n",
      "cubes = iris.load_raw(fname, 'surface_temperature')\n",
      "print len(cubes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we try to merge these 12 cubes we get 2 cubes rather than one:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "incomplete_cubes = cubes.merge(unique=False)\n",
      "print incomplete_cubes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: surface_temperature / (K)           (time: 6; latitude: 145; longitude: 192)\n",
        "1: surface_temperature / (K)           (time: 6; latitude: 145; longitude: 192)\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When we look in more detail at these two cubes, what is different between the two?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print incomplete_cubes[0]\n",
      "print '--' * 50\n",
      "print incomplete_cubes[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "surface_temperature / (K)           (time: 6; latitude: 145; longitude: 192)\n",
        "     Dimension coordinates:\n",
        "          time                           x            -               -\n",
        "          latitude                       -            x               -\n",
        "          longitude                      -            -               x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x            -               -\n",
        "     Scalar coordinates:\n",
        "          forecast_reference_time: 2011-07-19 00:00:00\n",
        "     Attributes:\n",
        "          STASH: m01s00i024\n",
        "          source: Data from Met Office Unified Model 7.06\n",
        "     Cell methods:\n",
        "          mean: time (1 hour)\n",
        "----------------------------------------------------------------------------------------------------\n",
        "surface_temperature / (K)           (time: 6; latitude: 145; longitude: 192)\n",
        "     Dimension coordinates:\n",
        "          time                           x            -               -\n",
        "          latitude                       -            x               -\n",
        "          longitude                      -            -               x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x            -               -\n",
        "     Scalar coordinates:\n",
        "          forecast_reference_time: 2011-07-20 00:00:00\n",
        "          realization: 4\n",
        "     Attributes:\n",
        "          STASH: m01s00i024\n",
        "          source: Data from Met Office Unified Model 7.06\n",
        "     Cell methods:\n",
        "          mean: time (1 hour)\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By adding the missing coordinate, we can trigger a merge of the 12 cubes into a single cube, as expected:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for cube in cubes:\n",
      "    if not cube.coords('realization'):\n",
      "        cube.add_aux_coord(iris.coords.DimCoord(np.int32(3), 'realization'))\n",
      "\n",
      "merged_cubes = cubes.merge()\n",
      "print merged_cubes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: surface_temperature / (K)           (time: 6; forecast_reference_time: 2; latitude: 145; longitude: 192)\n"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print merged_cubes[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "surface_temperature / (K)           (time: 6; forecast_reference_time: 2; latitude: 145; longitude: 192)\n",
        "     Dimension coordinates:\n",
        "          time                           x                           -            -               -\n",
        "          forecast_reference_time        -                           x            -               -\n",
        "          latitude                       -                           -            x               -\n",
        "          longitude                      -                           -            -               x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x                           x            -               -\n",
        "          realization                    x                           x            -               -\n",
        "     Attributes:\n",
        "          STASH: m01s00i024\n",
        "          source: Data from Met Office Unified Model 7.06\n",
        "     Cell methods:\n",
        "          mean: time (1 hour)\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "At the time of writing (iris v1.5) there are two known limitations which prevent merging and should be removed in a future version:\n",
      "\n",
      " * cubes with differing **var_name** attributes\n",
      " * cubes with different \"data manager\" states (loaded vs not-loaded, different slices but same data shape, different data types)\n",
      "\n",
      "### Exercise 4\n",
      "\n",
      "The following exercise is designed to give you experience of identifying why two cubes are not merging. Work is underway to make this identification process more automatic, but the resolution of the identified differences will still be a necessary process.\n",
      "\n",
      "There are 6 problems, each of which are not merging into a single cube as desired. In no particular order the problems are:\n",
      "\n",
      " 1. one of the cubes has a history attribute, but the other doesn't\n",
      " 2. one of the cubes has bounds on the spatial coordinates, but the other doesn't\n",
      " 3. the two cubes have different time coordinate units\n",
      " 4. the two cubes have different data dtypes\n",
      " 5. the two cubes have different long names\n",
      " 6. the two cubes have different shapes (the data must currently be loaded to correct this)\n",
      " \n",
      "The files can be found in the repository along with this course in ```resources/```. There are two files to be loaded for each exercise: ```merge_exercise.{problem_number}.f1.nc``` and ```merge_exercise.{problem_number}.f2.nc```.\n",
      "\n",
      "Identify, and correct, the reason that the two cubes are not merging for all 6 sets of files.\n",
      "\n",
      "The first problem is solved below:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cubes = iris.load('resources/merge_exercise.1.*.nc')\n",
      "if len(cubes) > 1:\n",
      "    print 'Unsucessful merge.\\n', cubes\n",
      "\n",
      "print cubes[0].attributes\n",
      "print cubes[1].attributes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Unsucessful merge.\n",
        "0: air_potential_temperature / (K)     (grid_latitude: 100; grid_longitude: 100)\n",
        "1: air_potential_temperature / (K)     (grid_latitude: 100; grid_longitude: 100)\n",
        "{'source': 'Iris test case', 'Conventions': 'CF-1.5', 'History': 'unknown'}\n",
        "{'source': 'Iris test case', 'Conventions': 'CF-1.5'}\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that in this case, it is the attributes dictionary that is preventing us from merging."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cubes[0].attributes.pop('History')\n",
      "print cubes.merge()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0: air_potential_temperature / (K)     (time: 2; grid_latitude: 100; grid_longitude: 100)\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Load callbacks\n",
      "\n",
      "Sometimes important data exists in a filename rather than in the file itself which should be part of the cube's metadata.\n",
      "For example, some early GloSea4 model runs recorded the \"ensemble member number\" (or \"realization\" in CF terms) in the filename, but not in actual PP metadata itself. As a result, loading the data yielded 2 cubes, rather than a single, fully merged, cube."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = iris.sample_data_path('GloSea4', 'ensemble_00[34].pp')\n",
      "for cube in iris.load(fname, 'surface_temperature'):\n",
      "    print cube, '\\n-----'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "surface_temperature / (K)           (time: 6; latitude: 145; longitude: 192)\n",
        "     Dimension coordinates:\n",
        "          time                           x            -               -\n",
        "          latitude                       -            x               -\n",
        "          longitude                      -            -               x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x            -               -\n",
        "     Scalar coordinates:\n",
        "          forecast_reference_time: 2011-07-19 00:00:00\n",
        "     Attributes:\n",
        "          STASH: m01s00i024\n",
        "          source: Data from Met Office Unified Model 7.06\n",
        "     Cell methods:\n",
        "          mean: time (1 hour) \n",
        "-----\n",
        "surface_temperature / (K)           (time: 6; latitude: 145; longitude: 192)\n",
        "     Dimension coordinates:\n",
        "          time                           x            -               -\n",
        "          latitude                       -            x               -\n",
        "          longitude                      -            -               x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x            -               -\n",
        "     Scalar coordinates:\n",
        "          forecast_reference_time: 2011-07-20 00:00:00\n",
        "          realization: 4\n",
        "     Attributes:\n",
        "          STASH: m01s00i024\n",
        "          source: Data from Met Office Unified Model 7.06\n",
        "     Cell methods:\n",
        "          mean: time (1 hour) \n",
        "-----\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To resolve this we can define a function which gets called during the load process which takes a cube, a PP field and a filename, and makes the necessary adjustments to include a \"realization\" coordinate. We pass this function to load, and the result is a successfully merged cube:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "def realization_callback(cube, field, fname):\n",
      "    basename = os.path.basename(fname)\n",
      "    if not cube.coords('realization') and basename.startswith('ensemble_'):\n",
      "        cube.add_aux_coord(iris.coords.DimCoord(np.int32(basename[-6:-3]), 'realization'))\n",
      "\n",
      "print iris.load_cube(fname, callback=realization_callback)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "surface_temperature / (K)           (time: 6; forecast_reference_time: 2; latitude: 145; longitude: 192)\n",
        "     Dimension coordinates:\n",
        "          time                           x                           -            -               -\n",
        "          forecast_reference_time        -                           x            -               -\n",
        "          latitude                       -                           -            x               -\n",
        "          longitude                      -                           -            -               x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x                           x            -               -\n",
        "          realization                    x                           x            -               -\n",
        "     Attributes:\n",
        "          STASH: m01s00i024\n",
        "          source: Data from Met Office Unified Model 7.06\n",
        "     Cell methods:\n",
        "          mean: time (1 hour)\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Indexing\n",
      "\n",
      "Cubes can be indexed in a familiar manner to that of numpy arrays:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = iris.sample_data_path('uk_hires.pp')\n",
      "cube = iris.load_cube(fname, 'air_potential_temperature')\n",
      "print cube.summary(shorten=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (time: 3; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subcube = cube[..., ::2, 15:35, :10]\n",
      "subcube.summary(shorten=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "'air_potential_temperature / (K)     (time: 3; model_level_number: 4; grid_latitude: 20; grid_longitude: 10)'"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note: the result of indexing a cube is *always* a copy."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Cube aggregation/collapsing\n",
      "\n",
      "Many standard univariate aggregations exist in Iris (and it is relatively easy to create your own, if the one you want doesn't exist)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = iris.sample_data_path('uk_hires.pp')\n",
      "cube = iris.load_cube(fname, 'air_potential_temperature')\n",
      "print cube.summary(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (time: 3; model_level_number: 7; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To take the vertical mean of this cube:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print cube.collapsed('model_level_number', iris.analysis.MEAN)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (time: 3; grid_latitude: 204; grid_longitude: 187)\n",
        "     Dimension coordinates:\n",
        "          time                           x                 -                    -\n",
        "          grid_latitude                  -                 x                    -\n",
        "          grid_longitude                 -                 -                    x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x                 -                    -\n",
        "          surface_altitude               -                 x                    x\n",
        "     Derived coordinates:\n",
        "          altitude                       -                 x                    x\n",
        "     Scalar coordinates:\n",
        "          forecast_reference_time: 2009-11-19 04:00:00\n",
        "          level_height: 696.667 m, bound=(0.0, 1393.33) m\n",
        "          model_level_number: 10, bound=(1, 19)\n",
        "          sigma: 0.92293, bound=(0.84586, 1.0)\n",
        "     Attributes:\n",
        "          STASH: m01s00i004\n",
        "          source: Data from Met Office Unified Model 7.03\n",
        "     Cell methods:\n",
        "          mean: model_level_number\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some of the aggregators accept ``weights`` as a keyword. The supplied weights must have the same shape as the cube (there is currently no broadcasting being done) and there is an iris utility function to make this easier (available after v1.5 only):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights = np.array([1, 1.1, 1, 1.4, 0.7, 1, 1])\n",
      "weights = iris.util.broadcast_to_shape(weights, cube.shape, (1,))\n",
      "print cube.collapsed('model_level_number', iris.analysis.MEAN, weights=weights).summary(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (time: 3; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For an area weighted mean there is a convenience function called ``area_weights`` in ``iris.analysis.cartography``. One of the requirements of this function is that the spatial coordinates have bounds (otherwise there would be no area to calculate):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import iris.analysis.cartography\n",
      "cube.coord('grid_latitude').guess_bounds()\n",
      "cube.coord('grid_longitude').guess_bounds()\n",
      "grid_areas = iris.analysis.cartography.area_weights(cube)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This can be passed to the collapsed method along with the two coordinates which we want to take the mean over:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "area_avg = cube.collapsed(['grid_longitude', 'grid_latitude'], iris.analysis.MEAN, weights=grid_areas)\n",
      "print area_avg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (time: 3; model_level_number: 7)\n",
        "     Dimension coordinates:\n",
        "          time                           x                      -\n",
        "          model_level_number             -                      x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x                      -\n",
        "          level_height                   -                      x\n",
        "          sigma                          -                      x\n",
        "     Derived coordinates:\n",
        "          altitude                       -                      x\n",
        "     Scalar coordinates:\n",
        "          forecast_reference_time: 2009-11-19 04:00:00\n",
        "          grid_latitude: 1.51455 degrees, bound=(0.13755, 2.89155) degrees\n",
        "          grid_longitude: 358.749 degrees, bound=(357.487, 360.012) degrees\n",
        "          surface_altitude: 399.625 m, bound=(-14.0, 813.25) m\n",
        "     Attributes:\n",
        "          STASH: m01s00i004\n",
        "          source: Data from Met Office Unified Model 7.03\n",
        "     Cell methods:\n",
        "          mean: grid_longitude, grid_latitude\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 5:** What other aggregators are available? Calculate the potential temperature variance with time for the area averaged cube (hint: We want to reduce the vertical dimension, and end up with a cube of length 3). Print the data values of the resulting cube."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Iteration\n",
      "\n",
      "We can loop through all desired subcubes in a larger cube using the ``slices`` method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = iris.sample_data_path('uk_hires.pp')\n",
      "cube = iris.load_cube(fname, iris.Constraint('air_potential_temperature', model_level_number=1))\n",
      "print cube.summary(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (time: 3; grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for subcube in cube.slices(['grid_latitude', 'grid_longitude']):\n",
      "    print subcube.summary(shorten=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_potential_temperature / (K)     (grid_latitude: 204; grid_longitude: 187)\n",
        "air_potential_temperature / (K)     (grid_latitude: 204; grid_longitude: 187)\n",
        "air_potential_temperature / (K)     (grid_latitude: 204; grid_longitude: 187)\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The ``iris.iterate.izip`` function extends this concept and allows us to step through multiple cubes at the same time:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from iris.iterate import izip\n",
      "\n",
      "e1 = iris.load_cube(iris.sample_data_path('E1_north_america.nc'))\n",
      "a1b = iris.load_cube(iris.sample_data_path('A1B_north_america.nc'))\n",
      "\n",
      "for e1_slice, a1b_slice in izip(e1, a1b, coords=['latitude', 'longitude']):\n",
      "    print e1_slice.summary(True)\n",
      "    print a1b_slice.summary(True)\n",
      "    break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_temperature / (K)               (latitude: 37; longitude: 49)\n",
        "air_temperature / (K)               (latitude: 37; longitude: 49)\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this example, one real use for this functionality would be to plot the ``e1`` cube next to the ``a1b`` for each timestep."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Plotting\n",
      "\n",
      "Iris comes with two modules which wrap some of the common matplotlib functions such that cubes can be passed as input, rather than the usual numpy arrays. The two modules are ``iris.plot`` and ``iris.quickplot``, and they are very similar, with the primary difference that quickplot will add extra information to the axes, such as a an appropriate colour map, a colorbar, x/y axis labels and a title where possible."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import iris.plot as iplt\n",
      "import iris.quickplot as qplt\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cube = iris.load_cube(iris.sample_data_path('A1B_north_america.nc'))\n",
      "ts = cube.collapsed(['latitude', 'longitude'], iris.analysis.MEAN)\n",
      "print ts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_temperature / (K)               (time: 240)\n",
        "     Dimension coordinates:\n",
        "          time                           x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x\n",
        "     Scalar coordinates:\n",
        "          forecast_reference_time: 1859-09-01 06:00:00\n",
        "          height: 1.5 m\n",
        "          latitude: 37.5 degrees, bound=(15.0, 60.0) degrees\n",
        "          longitude: 270.0 degrees, bound=(225.0, 315.0) degrees\n",
        "     Attributes:\n",
        "          Conventions: CF-1.5\n",
        "          Model scenario: A1B\n",
        "          STASH: m01s03i236\n",
        "          source: Data from Met Office Unified Model 6.05\n",
        "     Cell methods:\n",
        "          mean: time (6 hour)\n",
        "          mean: latitude, longitude\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iplt.plot(ts)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x3dd7050>"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For comparison, lets plot the result of ``iplt.plot`` next to ``qplt.plot``:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.subplot(2, 1, 1)\n",
      "iplt.plot(ts)\n",
      "\n",
      "plt.subplot(2, 1, 2)\n",
      "qplt.plot(ts)\n",
      "\n",
      "plt.subplots_adjust(hspace=0.5)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x340f410>"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice how the result of qplt has axis labels, and a title - everything else about the axes is identical."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The plotting functions in Iris have strict rules on the dimensionality of the inputted cubes. For example, a 2d cube is needed in order to create a contour plot:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "qplt.contourf(cube[:, 0, :])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x3885b50>"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Additionally, we can control the x and y axis coordinates with the **coords** keyword:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zonal_variance = cube.collapsed('longitude', iris.analysis.VARIANCE)\n",
      "qplt.contourf(zonal_variance, coords=['forecast_period', 'latitude'])\n",
      "plt.title('Zonal variance in air temperature')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x399d710>"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Maps with cartopy\n",
      "\n",
      "When the result of a plot operation is a map, iris will automatically create an appropriate cartopy axes if one doesn't already exist.\n",
      "\n",
      "We can use matplotlib's **gca()** to get hold of the automatically created cartopy axes:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cartopy.crs as ccrs\n",
      "\n",
      "plt.figure(figsize=(12, 8))\n",
      "\n",
      "plt.subplot(1, 2, 1)\n",
      "qplt.contourf(cube[0, ...], 25)\n",
      "ax = plt.gca()\n",
      "ax.coastlines()\n",
      "\n",
      "ax = plt.subplot(1, 2, 2, projection=ccrs.RotatedPole(100, 37))\n",
      "qplt.contourf(cube[0, ...], 25)\n",
      "ax.coastlines()\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x39bfe50>"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 6:** Use the above cube with, appropriate slicing, to produce the following:\n",
      "\n",
      " 1. a **contour** plot of *longitude* vs *time*\n",
      " 2. a **contourf** map on a LambertConformal projection (with coastlines)\n",
      " 3. a block plot (**pcolormesh**) map in its native projection  (with coastlines)\n",
      " 4. a line **plot** showing *forecast_period* vs *air_temperature* (hint: plot accepts two arguments for the x and y axes)\n",
      " 5. a **scatter** plot showing *longitude* vs *air_temperature*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Cube maths\n",
      "\n",
      "Basic mathematical operators exist on the cube to allow one to add/subtract/divide/multiply cubes of a similar shape to one another (currently there is no broadcasting, they must both be of the same dimensionality):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a1b = iris.load_cube(iris.sample_data_path('A1B_north_america.nc'))\n",
      "e1 = iris.load_cube(iris.sample_data_path('E1_north_america.nc'))\n",
      "\n",
      "print e1.summary(True)\n",
      "print a1b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "air_temperature / (K)               (time: 240; latitude: 37; longitude: 49)\n",
        "air_temperature / (K)               (time: 240; latitude: 37; longitude: 49)\n",
        "     Dimension coordinates:\n",
        "          time                           x              -              -\n",
        "          latitude                       -              x              -\n",
        "          longitude                      -              -              x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x              -              -\n",
        "     Scalar coordinates:\n",
        "          forecast_reference_time: 1859-09-01 06:00:00\n",
        "          height: 1.5 m\n",
        "     Attributes:\n",
        "          Conventions: CF-1.5\n",
        "          Model scenario: A1B\n",
        "          STASH: m01s03i236\n",
        "          source: Data from Met Office Unified Model 6.05\n",
        "     Cell methods:\n",
        "          mean: time (6 hour)\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scenario_difference = a1b - e1\n",
      "print scenario_difference"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "unknown / (K)                       (time: 240; latitude: 37; longitude: 49)\n",
        "     Dimension coordinates:\n",
        "          time                           x              -              -\n",
        "          latitude                       -              x              -\n",
        "          longitude                      -              -              x\n",
        "     Auxiliary coordinates:\n",
        "          forecast_period                x              -              -\n",
        "     Scalar coordinates:\n",
        "          forecast_reference_time: 1859-09-01 06:00:00\n",
        "          height: 1.5 m\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice that the resultant cube's name is now unknown and that the coordinates \u201ctime\u201d and \u201cforecast_period\u201d have been removed; this is because these coordinates differed between the two input cubes."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is also possible to operate on cubes with numeric scalars, arrays and even coordinates:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e1 * e1.coord('latitude')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "<iris 'Cube' of unknown / (0.0174532925199433 kelvin-radian) (time: 240; latitude: 37; longitude: 49)>"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However it is currently not possible to operate with cubes of different shapes. For example, a common task is to calculate the mean difference:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    e1 - e1.collapsed('time', iris.analysis.MEAN)\n",
      "except:\n",
      "    raise ValueError(\"It's not currently possible to subtract the mean from the dataset...\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are several alternative solutions to this limitation which currently exist. Supposing that we wanted to calculate the mean difference over time, and then immediately iterate over the time dimension, we could swap the order of operations such that we iterate over the time dimension and then for each time subtract the mean. If this is not the case, the last resort is to make use of numpy's broadcasting rules and to subtract the data values from one another:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_diff = e1.copy()\n",
      "mean_diff.rename('mean difference of air temperature')\n",
      "mean_diff.data = e1.data - e1.collapsed('time', iris.analysis.MEAN).data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Creating extra annotation coordinates for statistical convenience\n",
      "\n",
      "Sometimes we want to be able categorise data before performing statistical operations on it. For example, \"daylight maximum\" and \"seasonal mean\" etc.\n",
      "\n",
      "The ``iris.coord_categorisation`` module provides convenience functions to add some common categorical coordinates, and provides a generalised function to allow each creation of custom categorisations. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import iris.coord_categorisation as coord_cat\n",
      "\n",
      "filename = iris.sample_data_path('ostia_monthly.nc')\n",
      "cube = iris.load_cube(filename, 'surface_temperature')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The cube loaded represents the monthly air_temperature from April 2006 through to October 2010. Let's add categorisation to this cube to identify the climatological season (i.e \"djf\", \"mam\", \"jja\" or \"son\"):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coord_cat.add_season(cube, 'time', name='clim_season')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now use the cube's ``aggregated_by`` method to \"group by and aggregate\" on the season, to produce the seasonal mean:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "seasonal_mean = cube.aggregated_by('clim_season', iris.analysis.MEAN)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can take this further by extracting by our newly created coordinate, and producing a plot of the winter zonal mean:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "winter = seasonal_mean.extract(iris.Constraint(clim_season='djf'))\n",
      "\n",
      "qplt.plot(winter.collapsed('latitude', iris.analysis.MEAN))\n",
      "plt.title('Winter zonal mean surface temperature at $\\pm5^{\\circ}$ latitude')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x3e2a0d0>"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Custom categorisation can be created with an arbitrary function. For example, the already existing ``add_year`` categorisor takes the 'time' coordinate, and creates a 'year' coordinate. This could be achieved without using the available ``add_year`` by:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def year_from_time(coord, point):\n",
      "    return coord.units.num2date(point).year\n",
      "\n",
      "coord_cat.add_categorised_coord(cube, 'year', cube.coord('time'), year_from_time)\n",
      "\n",
      "print cube.coord('year')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "AuxCoord(array([2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2007, 2007,\n",
        "       2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2008,\n",
        "       2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008, 2008,\n",
        "       2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009,\n",
        "       2009, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010]), standard_name=None, units=Unit('1'), long_name=u'year')\n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Performance tricks\n",
      "\n",
      "A few common tricks to improve the performance of your iris code.\n",
      "\n",
      " * data loading\n",
      " * load once, extract many times"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Make use of deferred loading of data.** Sometimes it makes sense to load data before doing operations, other times it makes sense to do data reduction before loading:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def zonal_sum(cube):\n",
      "    \"\"\"\n",
      "    A really silly function to calculate the sum of the grid_longitude dimension.\n",
      "    Don't use this in real life, instead consider doing:\n",
      "    \n",
      "        cube.collapsed('grid_longitude', iris.analysis.SUM)\n",
      "    \n",
      "    \"\"\"\n",
      "    total = 0\n",
      "    for i, _ in enumerate(cube.coord('grid_longitude')):\n",
      "        total += cube[..., i].data\n",
      "    return total\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "fname = iris.sample_data_path('uk_hires.pp')\n",
      "pt = iris.load_cube(fname, 'air_potential_temperature')\n",
      "result = zonal_sum(pt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 3.49 s per loop\n"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The exact same code, only with the data loaded upfront:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "fname = iris.sample_data_path('uk_hires.pp')\n",
      "pt = iris.load_cube(fname, 'air_potential_temperature')\n",
      "pt.data\n",
      "result = zonal_sum(pt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 780 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Load once, extract many times.** Iris loading can be slow, particularly if the format stores 2d fields of a conceptually higher dimensional dataset, as is the case with GRIB and PP. To maximise load speed and avoid unncecessary processing, it is worth constraining the fields that are of interest *at load time*, but there is no caching, so loading a file twice will be twice as slow."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = iris.sample_data_path('uk_hires.pp')\n",
      "model_levels = [1, 4,  7, 16]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "for model_level in model_levels:\n",
      "    pt = iris.load_cube(fname, iris.Constraint('air_potential_temperature', model_level_number=model_level))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 327 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "cubes = iris.load(fname)\n",
      "for model_level in model_levels:\n",
      "    pt = cubes.extract(iris.Constraint('air_potential_temperature', model_level_number=model_level), strict=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10 loops, best of 3: 115 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For files with lots of different phenomenon this can be improved further by loading only the phenomenon (and in this case just the model levels of interest):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%timeit\n",
      "cube = iris.load(fname, iris.Constraint('air_potential_temperature', model_level_number=model_levels))\n",
      "for model_level in model_levels:\n",
      "    pt = cube.extract(iris.Constraint(model_level_number=model_level))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10 loops, best of 3: 107 ms per loop\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Thea\n",
      "\n",
      "Thea is a graphical user interface (GUI) which makes use of Iris.\n",
      "Created by summer placement student Mike Walker, it is designed to be a simple interface to quickly inspect the contents of any file which Iris can load. Thea will not become a fully fledged \"iris in a GUI\", rather its scope is intentionally limited to be a very useful and easy to use data inspection tool.\n",
      "\n",
      "https://github.com/scitools/thea\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 7\n",
      "\n",
      "1. Load 'A1B_north_america.nc' from the iris sample data\n",
      "2. Extract just data from the year 1980 and beyond from the loaded data\n",
      "3. Define a function which takes a coordinate and a single time point as arguments, and returns the decade. For example, your function should return 2010 for the following:\n",
      "\n",
      "       time = iris.coords.DimCoord([10], 'time', units='days since 2018-01-01')\n",
      "       print your_decade_function(time, time.points[0])\n",
      "\n",
      "4. Add a \"decade\" coordinate to the loaded cube using your function and the coord categorisation module\n",
      "5. Calculate the decadal means cube for this scenario\n",
      "6. Create a figure with 3 rows and 4 columns displaying the decadal means, with the decade displayed prominently in each axes' title"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}